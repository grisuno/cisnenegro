#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
NeuroSovereign v14.0: Hierarchical Apex (FIXED)
Objective: Prove Structural Necessity on CIFAR-100 (Hierarchical Task).
Features:
1. Dataset Upgrade: CIFAR-10 -> CIFAR-100 (Requires feature composition).
2. Gated Token Mixer: Content-aware mixing (not just static linear).
3. Gate Usage Metric: Implicit ablation to prove mixer activity.
"""
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
import numpy as np
import pandas as pd
import os
import warnings
from typing import Dict, Tuple
warnings.filterwarnings('ignore')

# =============================================================================
# CONFIGURATION
# =============================================================================
NUM_EVOLUTION_CYCLES = 12
INPUT_DIM = 384
FIXED_HIDDEN_DIM = 256
NUM_CLASSES = 100  # üîº CIFAR-100
TARGET_L = 1.8
UNFREEZE_AT_CYCLE = 3

# =============================================================================
# 1. ADVANCED MODULAR VISION EYE
# =============================================================================
class GatedTokenMixer(nn.Module):
    def __init__(self, num_tokens=64, embed_dim=384):
        super().__init__()
        # Mixer acts on the token dimension (spatial mixing)
        self.mixer = nn.Linear(num_tokens, num_tokens, bias=False)
        
        # Gate acts on the embedding dimension (channel-wise gating)
        self.gate = nn.Sequential(
            nn.Linear(embed_dim, embed_dim // 4),
            nn.GELU(),
            nn.Linear(embed_dim // 4, 1), # Outputs a scalar per token
            nn.Sigmoid()
        )
        
        nn.init.eye_(self.mixer.weight)
        with torch.no_grad():
            self.mixer.weight += torch.randn_like(self.mixer.weight) * 0.01
            
    def forward(self, x):
        # x input: [Batch, Tokens, Embed] 
        # 1. Spatial Mixing: Move Tokens to the last dim
        x_spat = x.transpose(1, 2)          # [B, Embed, Tokens]
        mixed = self.mixer(x_spat)          # [B, Embed, Tokens]
        mixed = mixed.transpose(1, 2)       # [B, Tokens, Embed]
        
        # 2. Content Gating: Gate based on original Embed dim
        g = self.gate(x)                    # [B, Tokens, 1]
        
        return x + g * mixed

class PatchFeatureExtractor(nn.Module):
    """
    Extractor configurable para CIFAR-100.
    use_mixer=True -> Apex (Syntactic)
    use_mixer=False -> Blind Structural Baseline
    """
    def __init__(self, img_size=32, patch_size=4, in_chans=3, embed_dim=384, use_mixer=True):
        super().__init__()
        self.num_patches = (img_size // patch_size) ** 2
        self.embed_dim = embed_dim
        self.use_mixer = use_mixer
        
        self.proj = nn.Conv2d(in_chans, embed_dim, kernel_size=patch_size, stride=patch_size)
        
        if self.use_mixer:
            self.mixer = GatedTokenMixer(self.num_patches, embed_dim)
        
        nn.init.trunc_normal_(self.proj.weight, std=0.02)
        if self.proj.bias is not None:
            nn.init.zeros_(self.proj.bias)
            
        self.freeze()

    def freeze(self):
        for param in self.parameters():
            param.requires_grad = False
            
    def unfreeze(self):
        for param in self.parameters():
            param.requires_grad = True

    def forward(self, x):
        x = self.proj(x) 
        x = x.flatten(2) 
        x = x.transpose(1, 2) 
        
        if self.use_mixer:
            x = self.mixer(x) 
        
        x = x.mean(dim=1) 
        return x

# =============================================================================
# 2. LOTTERY TICKET MLP (SHARED BRAIN)
# =============================================================================
class LotteryMLP(nn.Module):
    def __init__(self, input_dim: int = 384, hidden_dim: int = 256, num_classes: int = 100):
        super().__init__()
        self.fc1 = nn.Linear(input_dim, hidden_dim, bias=False)
        self.fc2 = nn.Linear(hidden_dim, num_classes, bias=False)
        
        self.register_buffer('mask1', torch.ones_like(self.fc1.weight))
        self.register_buffer('mask2', torch.ones_like(self.fc2.weight))
        
        nn.init.normal_(self.fc1.weight, mean=0.0, std=0.02)
        nn.init.normal_(self.fc2.weight, mean=0.0, std=0.02)

    def apply_masks(self):
        with torch.no_grad():
            self.fc1.weight.data *= self.mask1
            self.fc2.weight.data *= self.mask2

    def get_sparsity(self):
        total = self.mask1.numel() + self.mask2.numel()
        active = self.mask1.sum() + self.mask2.sum()
        return (1.0 - (active.item() / total)) * 100

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        w1 = self.fc1.weight * self.mask1
        w2 = self.fc2.weight * self.mask2
        x = F.relu(F.linear(x, w1))
        return F.linear(x, w2)

# =============================================================================
# 3. MONITORING
# =============================================================================
class SpectralMonitor:
    def compute_metrics(self, weight: torch.Tensor) -> Tuple[float, int, float]:
        with torch.no_grad():
            W = weight.cpu().numpy()
            U, S, Vh = np.linalg.svd(W, full_matrices=False)
            threshold = 0.05 * np.max(S)
            rank_eff = max(1, int(np.sum(S > threshold)))
            S_norm = S / (np.sum(S) + 1e-12)
            S_norm = S_norm[S_norm > 1e-15]
            S_vN = -np.sum(S_norm * np.log(S_norm + 1e-15))
            L = 1.0 / (abs(S_vN - np.log(rank_eff + 1)) + 0.3)
            return L, rank_eff, S_vN

# =============================================================================
# 4. ORTHOGONAL ENGINE
# =============================================================================
class OrthogonalEvolutionEngine:
    def __init__(self, device: torch.device):
        self.device = device
        self.monitor = SpectralMonitor()
        self.input_dim = INPUT_DIM

    def _gradient_nudge_inheritance(self, 
                                     child_model: nn.Module, 
                                     elk_state: Dict, 
                                     data_loader, 
                                     feature_extractor,
                                     nudge_lr: float = 0.005):
        temp_elk = LotteryMLP(input_dim=self.input_dim, hidden_dim=FIXED_HIDDEN_DIM, num_classes=NUM_CLASSES).to(self.device)
        temp_elk.load_state_dict(elk_state)
        temp_elk.train()
        
        optimizer = torch.optim.SGD(temp_elk.parameters(), lr=nudge_lr)
        criterion = nn.CrossEntropyLoss()
        
        for inputs, labels in data_loader:
            inputs, labels = inputs.to(self.device), labels.to(self.device)
            # FIX FOR ERROR: Asegurar que labels sea long
            labels = labels.long() 
            
            with torch.no_grad():
                inputs_features = feature_extractor(inputs)
            
            optimizer.zero_grad()
            outputs = temp_elk(inputs_features)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            break
        
        with torch.no_grad():
            child_model.fc1.weight.data = temp_elk.fc1.weight.data
            child_model.mask1.data = temp_elk.mask1.data
            child_model.fc2.weight.data = temp_elk.fc2.weight.data
            child_model.mask2.data = temp_elk.mask2.data

    def _apply_rank_capping_shock(self, model: nn.Module, layer_name='fc1', keep_ratio=0.85):
        layer = getattr(model, layer_name)
        W = layer.weight.data
        U, S, V = torch.svd(W)
        max_rank = S.shape[0]
        target_rank = int(max_rank * keep_ratio)
        mask = torch.zeros_like(S)
        mask[:target_rank] = 1.0
        S_capped = S * mask
        W_shocked = U @ torch.diag(S_capped) @ V.t()
        
        with torch.no_grad():
            layer.weight.data = W_shocked
            new_mask = (torch.abs(W_shocked) > 1e-5).float()
            if layer_name == 'fc1':
                model.mask1.copy_(new_mask)
            else:
                model.mask2.copy_(new_mask)

    def create_refined_offspring(self, elk_state: Dict, data_loader, feature_extractor) -> nn.Module:
        # FIXED: Moved 'child' to a new line with proper indentation
        child = LotteryMLP(input_dim=self.input_dim, hidden_dim=FIXED_HIDDEN_DIM, num_classes=NUM_CLASSES).to(self.device)
        child.fc1.weight.data = elk_state['fc1.weight']
        child.fc2.weight.data = elk_state['fc2.weight']
        child.mask1.data = elk_state['mask1']
        child.mask2.data = elk_state['mask2']

        self._gradient_nudge_inheritance(child, elk_state, data_loader, feature_extractor, nudge_lr=0.01)
        return child

# =============================================================================
# 5. HIERARCHICAL TRAINER
# =============================================================================
class HierarchicalTrainer:
    def __init__(self, device: torch.device, extractor_apex=None, extractor_blind=None):
        self.device = device
        self.extractor_apex = extractor_apex
        self.extractor_blind = extractor_blind
        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
        self.monitor = SpectralMonitor()
        self.engine = OrthogonalEvolutionEngine(device)

    def _preprocess_batch(self, x, extractor):
        with torch.no_grad():
            return extractor(x)

    def get_curriculum_dataset(self, cycle: int):
        full_trainset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=self.transform)
        sizes = {1: 5000, 4: 20000, 7: 50000} 
        size = sizes.get(cycle, 5000)
        return torch.utils.data.Subset(full_trainset, torch.randperm(len(full_trainset))[:size])

    def train_single_chain(self, model, cycle, chain_type='APEX'):
        trainset = self.get_curriculum_dataset(cycle)
        trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)
        
        testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=self.transform)
        testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False)
        
        wd = 0.1 if cycle < 5 else 0.01
        optimizer = torch.optim.AdamW(model.parameters(), lr=0.005, weight_decay=wd)
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)
        criterion = nn.CrossEntropyLoss()
        
        best_gap = 100.0
        best_acc = 0.0
        best_state = None
        
        extractor = self.extractor_apex if chain_type == 'APEX' else self.extractor_blind
        
        for epoch in range(100):
            model.train()
            train_correct, train_total = 0, 0
            
            for inputs, labels in trainloader:
                inputs, labels = inputs.to(self.device), labels.to(self.device)
                # FIX FOR ERROR: Asegurar labels es long
                labels = labels.long()
                
                inputs_proc = self._preprocess_batch(inputs, extractor)
                
                optimizer.zero_grad()
                outputs = model(inputs_proc)
                ce_loss = criterion(outputs, labels)
                ce_loss.backward()
                
                model.fc1.weight.grad *= model.mask1
                model.fc2.weight.grad *= model.mask2
                
                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)
                optimizer.step()
                
                _, predicted = torch.max(outputs.data, 1)
                train_total += labels.size(0)
                train_correct += (predicted == labels).sum().item()
            
            train_acc = 100 * train_correct / train_total
            
            model.eval()
            test_correct, test_total = 0, 0
            with torch.no_grad():
                for inputs, labels in testloader:
                    inputs, labels = inputs.to(self.device), labels.to(self.device)
                    labels = labels.long()
                    inputs_proc = self._preprocess_batch(inputs, extractor)
                    outputs = model(inputs_proc)
                    _, predicted = torch.max(outputs.data, 1)
                    test_total += labels.size(0)
                    test_correct += (predicted == labels).sum().item()
            
            test_acc = 100 * test_correct / test_total
            gap = train_acc - test_acc
            
            if test_acc > best_acc:
                best_acc = test_acc
                best_gap = gap
                best_state = model.state_dict().copy()
            
            L, rank_eff, _ = self.monitor.compute_metrics(model.fc1.weight)
            if epoch in [40, 80] and (gap > 20.0 or rank_eff > (FIXED_HIDDEN_DIM * 0.7)):
                self.engine._apply_rank_capping_shock(model, 'fc1', keep_ratio=0.85)
            
            if epoch % 20 == 0:
                spar = model.get_sparsity()
                print(f"         [{chain_type}] Ep {epoch:3d} | V:{test_acc:5.1f}% | Gap:{gap:4.1f} | L:{L:.3f} | Spar:{spar:.1f}%")
            
            scheduler.step()
            
        if best_state: 
            model.load_state_dict(best_state)
            model.apply_masks()
                
        L_final, Rank_final, _ = self.monitor.compute_metrics(model.fc1.weight)
        return {'final_acc': best_acc, 'final_gap': best_gap, 'L': L_final, 'rank': Rank_final}

# =============================================================================
# 6. MAIN EXECUTION
# =============================================================================
def main():
    print("=" * 90)
    print(" " * 20 + "NEUROSOVEREIGN v14.0: HIERARCHICAL APEX (FIXED)")
    print("=" * 90)
    print(f"Objective: Prove Structural Necessity on CIFAR-100.")
    print(f"Chain A: APEX (ViT-Lite + Mixer)")
    print(f"Chain B: BLIND (ViT-Lite + No Mixer)")
    print("=" * 90)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    
    extractor_apex = PatchFeatureExtractor(embed_dim=INPUT_DIM, use_mixer=True).to(device)
    extractor_blind = PatchFeatureExtractor(embed_dim=INPUT_DIM, use_mixer=False).to(device)
    
    trainer = HierarchicalTrainer(device, extractor_apex, extractor_blind)
    
    # ============================
    # 1. INITIALIZE DUAL ELKS
    # ============================
    if os.path.exists('alpha_elk_v14_apex.pth'):
        print("üìÇ Loading Dual Alphas v14...")
        elk_state_apex = torch.load('alpha_elk_v14_apex.pth', map_location=device)
        elk_state_blind = torch.load('alpha_elk_v14_blind.pth', map_location=device)
        start_cycle = 1
    else:
        print("ü•ö Generating Seed Elks (CIFAR-100)...")
        seed_apex = LotteryMLP(input_dim=INPUT_DIM, hidden_dim=FIXED_HIDDEN_DIM, num_classes=NUM_CLASSES).to(device)
        seed_blind = LotteryMLP(input_dim=INPUT_DIM, hidden_dim=FIXED_HIDDEN_DIM, num_classes=NUM_CLASSES).to(device)
        
        print("   - Seeding Apex...")
        trainer.train_single_chain(seed_apex, 0, 'APEX')
        print("   - Seeding Blind...")
        trainer.train_single_chain(seed_blind, 0, 'BLIND')
        
        elk_state_apex = seed_apex.state_dict()
        elk_state_blind = seed_blind.state_dict()
        start_cycle = 1
        torch.save(elk_state_apex, 'alpha_elk_v14_apex.pth')
        torch.save(elk_state_blind, 'alpha_elk_v14_blind.pth')

    # ============================
    # 2. DUAL EVOLUTION LOOP
    # ============================
    evolution_log = []
    
    for cycle in range(start_cycle, NUM_EVOLUTION_CYCLES + 1):
        print(f"\n{'='*90}")
        print(f"üî¨ HIERARCHICAL ISOLATION CYCLE {cycle}/{NUM_EVOLUTION_CYCLES}")
        print(f"{'='*90}")
        
        if cycle == UNFREEZE_AT_CYCLE:
            print("   üëÅÔ∏è  UNFREEZING BOTH EXTRACTORS...")
            extractor_apex.unfreeze()
            extractor_blind.unfreeze()
            
        curr_trainset = trainer.get_curriculum_dataset(cycle)
        curr_loader = torch.utils.data.DataLoader(curr_trainset, batch_size=64)
        
        # --- APEX ---
        parent_gap_apex = evolution_log[-1]['gap_apex'] if evolution_log else 20.0
        child_apex = trainer.engine.create_refined_offspring(elk_state_apex, curr_loader, extractor_apex)
        res_apex = trainer.train_single_chain(child_apex, cycle, 'APEX')
        
        # --- BLIND ---
        parent_gap_blind = evolution_log[-1]['gap_blind'] if evolution_log else 20.0
        child_blind = trainer.engine.create_refined_offspring(elk_state_blind, curr_loader, extractor_blind)
        res_blind = trainer.train_single_chain(child_blind, cycle, 'BLIND')
        
        # --- SELECCI√ìN ---
        improved_apex = res_apex['final_acc'] - (evolution_log[-1]['acc_apex'] if evolution_log else 0)
        if improved_apex >= 0.5 and abs(res_apex['L'] - TARGET_L) < 0.6:
            print(f"   ‚úÖ APEX EVOLVED ({improved_apex:+.1f})")
            elk_state_apex = child_apex.state_dict()
            torch.save(elk_state_apex, 'alpha_elk_v14_apex.pth')
        else:
            print(f"   ‚ùå APEX STAGNANT")

        improved_blind = res_blind['final_acc'] - (evolution_log[-1]['acc_blind'] if evolution_log else 0)
        if improved_blind >= 0.5 and abs(res_blind['L'] - TARGET_L) < 0.6:
            print(f"   ‚úÖ BLIND EVOLVED ({improved_blind:+.1f})")
            elk_state_blind = child_blind.state_dict()
            torch.save(elk_state_blind, 'alpha_elk_v14_blind.pth')
        else:
            print(f"   ‚ùå BLIND STAGNANT")
            
        delta_structure = res_apex['final_acc'] - res_blind['final_acc']
        
        evolution_log.append({
            'cycle': cycle,
            'acc_apex': res_apex['final_acc'],
            'acc_blind': res_blind['final_acc'],
            'delta_structure': delta_structure,
            'gap_apex': res_apex['final_gap'],
            'gap_blind': res_blind['final_gap'],
            'L_apex': res_apex['L'],
            'L_blind': res_blind['L'],
            'spar_apex': child_apex.get_sparsity(),
            'spar_blind': child_blind.get_sparsity()
        })

    # ============================
    # 3. ISOLATION REPORT
    # ============================
    df = pd.DataFrame(evolution_log)
    print("\n" + "=" * 90)
    print(" " * 30 + "CONTROLLED ISOLATION REPORT")
    print("=" * 90)
    
    disp_cols = ['cycle', 'acc_apex', 'acc_blind', 'delta_structure', 'gap_apex', 'gap_blind', 'L_apex', 'L_blind']
    print(df[disp_cols].to_string(index=False))
    
    print("-" * 90)
    print(f"üî¨ FINAL COMPARISON:")
    print(f"   Apex Best:   {df['acc_apex'].max():.2f}%")
    print(f"   Blind Best:  {df['acc_blind'].max():.2f}%")
    print(f"   Structure Œî: {df['delta_structure'].mean():.2f}%")
    
    if df['delta_structure'].mean() > 2.0:
        print("\n‚úÖ STRUCTURAL VALIDATED:")
        print("   Token Mixing consistently outperforms Structural Baseline")
        print("   while maintaining fixed capacity and same evolutionary pressure.")
    elif df['delta_structure'].mean() > 0.5:
        print("\n‚úÖ TREND VALIDATED:")
        print("   Token Mixing shows slight advantage over baseline.")
    else:
        print("\n‚ö†Ô∏è  NO STRUCTURAL ADVANTAGE:")
        print("   Baseline performs equally. The mixing adds no value in this setup.")
        
    print("=" * 90)

if __name__ == "__main__":
    main()